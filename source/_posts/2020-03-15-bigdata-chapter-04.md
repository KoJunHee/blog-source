---
layout: post
title:  "[빅데이터] 4장_일괄 처리 계층의 데이터 저장소"
date:   2020-03-15
categories: Big Data
---

마스터 데이터 집합은하나의 서버에 저장하기에는 너무 크다. 데이터를 여러 장비에 어떻게 분산시킬 것인지기 중요하다.
이번 장은 다음을 정리한다.

1. 마스터 데이터 집합을 저장하는데 필요한 요구사항
2. 분산 파일 시스템이 왜 데이터 집합을 저장하는데 적합한지

#### 4.1 마스터 데이터 집합 저장소의 요구사항

"데이터를 한 번만 쓰고, 읽기는 큰 단위로 여러 번 수행된다" 방식에 초점을 두면, 다음과 같이 요구사항을 정리할 수 있다.

- 쓰기
  - 데이터 추가의 효율성 : 유일한 쓰기 연산은 새로운 데이터를 추가하는 것뿐이다.
  - 확장성 있는 저장소 : 데이터 집합이 커질 때 확장하기 쉬워야한다.

- 읽기
  - 병렬 처리 지원 : 거대한 양의 데이터를 확장성 있는 방식으로 다룰 수 있도록 병렬 처리를 지원해야한다.
- 둘 다
  - 저장 비용과 처리 비용 조율 : 필요에 따라 데이터를 저장학고 압축하는 방식을 선택하는 유연성이 있어야한다.
  - 불변성 강제

#### 4.2 일괄 처리 계층을 위한 저장소 솔루션 선택

##### 4.2.1 키/값 저장소

여러 장비에 분산되는 거대하고 영속적인 hash map

1. 값은 저장할 데이터이다. 키는 무엇일까 ? 우리가 사용하는 데이터 모델에는 데이터 자체가 대량 소비를 전제로 한다. 그래서 원래 키가 없고, 필요하지도 않다. 즉, 처음 부터 데이터 모델과 키/값 저장소의 동작 방식이 맞지 않는 것이다. 유일하게 쓸만한 방법이라면, UUID 를 생성해서 키로 사용하는 것이다.
2. 키/값 저장소는 무작위 읽기와 쓰기를 지원하기 위해 키/값 쌍에 세밀하게 접근해야한다. 그래서, 여러 개의 키/값 쌍을 묶어서 압축하는 것도 불가능하다.
3. 키/값 저장소는 변경 가능한 저장소에 사용하도록 만들어져서, 마스터 데이터 집합에 불변성을 강제하는 게 극히 필요한 경우라면 문제가 된다.
4. 키/값 저장소에는 불필요한 기능이 많다. 무작위 읽기, 쓰기 그리고 이들을 가능하게 하는 모든 장치들이 이에 해당된다.
5. 데이터 색인을 하며 우리에게는 필요 없는 서비스도 제공해서 저장소 비용이 증가하고 데이터를 읽고 쓰는 성능이 저하될 수 있다.

##### 4.2.2 분산 파일 시스템

파일은 디스크에 순차적으로 저장된다. 파일에 들어있는 바이트는 완전히 제어할 수 있고 압축도 가능하다. 파일 시스템은 딱 필요한 기능만 제공하고 세밀한 권한 시스템으로 구현되어 있어서 불변성을 강제할 수 있다.
보통의 파일시스템의 문제는, 오직 하나의 장비에만 존재한다는 것이다. 그래서, 확장하려고 해도 단일 장비가 제공하는 저장소 크기와 처리 용량에 제한된다. 하지만, **저장소가 컴퓨터 클러스터에 나뉘어져 있는 분산 파일 시스템** 이 있다. 클러스터에 장비를 추가함으로써 규모가 확장된다. 또한, 장비가 한 대 죽더라도 모든 파일과 데이터에 접근할 수 있다. (내결함성)
분산 파일 시스템과 일반적인 파일 시스템은 조금 다르다. 분산 파일시스템에서 수행가능한 연산은 제한적이다. 예를 들어, 파일 중간에 쓸 수 없고, 파일을 만든 후에 변경이 불가능하다. 또, 작은 파일은 비효율적이라서 파일 크기를 상대적으로 크게 유지해야한다. (64MB 정도가 일반적)

#### 4.3 분산 파일시스템의 동작 방식

하둡 분산 파일 시스템 (HDFS) 를 예로 들자.
HDFS 와 Hadoop MapReduce 는, **대용량 데이터를 저장하고 처리하기 위한 자바 프레임워크인 하둡** 프로젝트의 구성 요소이다. 하둡은 클러스터라고 부르는 여러 서버에 배포되고, HDFS 는 확장성 있는 파일 시스템으로 클러스터에 데이터가 어떻게 저장될지를 관리한다.
HDFS 에는 두 종류의 노드가 있다 : 하나의 네임 노드와 복수 개의 데이터노드
파일을 HDFS 에 올리면, 그 파일은 먼저 고정된 크기의 블록으로 쪼개진다. 블록 크기는 보통 64MB ~ 256MB 이다. 그리고, 각 블록은 임의의 선택된 복수개의 (보통 3개) 데이터 노드로 복제된다. 프로그램이 HDFS 에 저장된 파일에 접근할 때는 파일 내용을 보관하고 있는 데이터 노드를 알아내기 위해 네임노드에 접속한다.
각각의 블록이 추가적으로 여러 노드에 복제되어 있어서, 개별 노드가 오프라인 상태가 되어도 데이터는 여전히 사용 가능하다.

![](/image/bigdata-hdfs.png)

#### 4.4 분산 파일 시스템을 사용해서 마스테 데이터 집합을 저장하기

파일을 한번 생성한 후에 변경할 수 없는 가장 기본적인 분산 파일시스템을 사용해보자.
파일을 변경할 수 없다면 당연히 마스터 데이터 집합 전체를 하나의 파일에 저장할 수 없다. 다른 방법으로, 마스터 데이터 집합을 여러 파일로 나누고 모든 파일을 동일한 폴더에 저장하면 된다. 각 파일에는 직렬화된 데이터 객체가 들어있다.
마스터 데이터 집합에 데이터를 추가하려면, 새로운 데이터 객체를 가지고 있는 새로운 파일을 마스터 데이터 집합 폴더에 추가하면 된다. 

![](/image/bigdata-master-data.png)

#### 4.5 수직분할

일괄 처리 계층은 전체 데이터 집합에 대한 함수를 실행하도록 만들어졌다. 하지만, 데이터 전체를 사용할 필요가 없는 계산도 있다. 예를 들면, 지난 두 주 동안 수집된 정보만 필요한 계산도 있을 수 있다.
일괄 처리 저장소는 데이터를 분할하여 **함수가 자신의 계산과 관련있는 데이터에만 접근**하록 해야한다. 이것이 수직분할이다. 일괄 처리 계층을 효율적으로 만든다.
데이터를 개개의 폴더에 저장하는 걸로 구현할 수 있다. 예를 들어, 분산 파일 시스템에 로그인 정보를 저장한다고 하자. 각각의 로그인 정보에는 사용자 이름 / IP / 주소 / 타임스탬프가 포함된다. 날짜를 기준으로 수직분할 하면, 그날 그날의 데이터에 사용할 독립적인 폴더를 만들면 된다.
이제 일부 데이터 집합에만 접근하고 싶으면, 특정 폴더에 있는 파일만 보고 나머지 파일은 무시할 수 있다.

![](/image/bigdata-columnar.png)

#### 4.6 분산 파일 시스템의 하위 수준 속성

분산 파일 시스템 API 를 직접 사용하는 것은 실행해야 하는 작업에 비해, 너무 하위 수준이다.
마스터 데이터 집합에 데이터를 추가하는 예를 보자. 마스터 데이터 집합은 /master 폴더에 있다. 마스터 데이터 집합에 추가하고 싶은 데이터는 /new-data 폴더에 있다. 폴더에 있는 데이터는 파일에 저장된다.

![](/image/bigdata-low-level.png)

가장 뻔한 방법은 다음 의사 코드 처럼 하는 것이다.

```
foreach file:"/new-data"
	mv file "/master"
```

결함이 있다. 만약, 마스터 데이터 집합 폴더에 이름이 같은 파일이 있으면 mv 연산은 실패한다. 파일의 이름을 임의의 이름으로 바꿔서 충돌을 회피해야한다.
또한, /new-data 에 있는 파일과 /master 에 있는 파일의 형식이 다르면, mv 연산은 작동하지 않는다. 그래서, /new-data 에 있는 레코드를 복사해서 /master 에 있는 파일 포맷과 동일한 새로운 파일을 만들어야한다.
수직 분할 된 마스터 데이터 집합에 동일한 작업을 해보자.

![](/image/bigdata-columnar-master-data.png)

/master 의 수직 분할을 따르지 않기 때문에, /new-data 에 있는 파일을 /master 의 최상위 경로로 바로 옮기면 안된다. 데이터 추가 연산을 허용하지 않거나, /new-data 에 대해 데이터 추가 연산의  부분으로 수직 분할을 해야한다.
그런데, 여기에 파일 및 폴더용 API 를 직접 사용하면 실수를 저지르기 쉽고 데이터 집합의 수직분할도 쉽게 깨질 수 있다. 이런 작업을 바르게 처리하기 위해 일일히 필요한 연산과 점검을 챙겨야 하는 것은, 파일과 폴더는 데이터 집합을 조작하기에는 추상화 수준이 너무 낮다는 것을 의미한다.
이러한 작업을 자동화해주는 라이브러리들을 다음 장에서 정리하자.

---

빅데이터, 람다 아키텍처로 알아보는 실시간 빅데이터 구축의 핵심 원리와 기법 <네이선 마츠, 제임스 워렌>

