---
layout: post
title:  "[빅데이터를 지탱하는 기술] 1장_빅데이터 기초 지식"
date:   2019-12-30
categories: Big Data
---

## 1.빅데이터의 정착

##### 빅데이터 기술의 요구 : Hadoop 과 NoSQL 의 대두

세계 곳곳에서 엑세스 되는 시스템 증가로, 전통적인 관계형 데이터베이스로는 취급 할 수 없는 데이터가 쌓이게 되었다.
그래서 다른 구조가 필요했다.

1. Hadoop
   다수의 컴퓨터에서 대량의 데이터 처리

2. NoSQL Database
   빈번한 읽기/ 쓰기 및 분산처리가 강점

##### 분산 시스템의 비즈니스 이용 개척 : 데이터 웨어하우스와의 공존 

![](/image/bigdata_datawarehouse.png)

위 그림처럼, 확장성이 뛰어난 Hadoop 에 데이터 처리를 맡겨 데이터 웨어하우스의 부하를 줄이고 있다.

##### 직접 할 수 있는 데이터 분석 폭 확대

'여러 컴퓨터에서 분산 처리한다' 는 빅데이터의 특징으로 하드웨어를 준비하고 관리하는게 어려웠다.
하지만, 클라우드 시대에서는 필요한 자원 확보가 쉬워서 얼마든지 빅데이터를 이용할 수 있다.

##### 데이터 디스커버리의 기초 지식

1. 데이터 디스커버리
   대화형으로 데이터를 시각화하여 가치있는 정보를 찾으려고하는 프로세스

2. BI 도구
   데이터 디스커버리를 위한 셀프 서비스용 시각화 시스템

## 2. 빅데이터 시대의 데이터 분석 기반

빅데이터 기술이 기존 데이터 웨어하우스와 다른 점은,
다수의 분산 시스템을 조합하여 확장성이 뛰어난 데이터 처리 구조를 만든다는 것이다.

##### 데이터 파이프라인

![](/image/bigdata_data_pipeline.png)

차례대로 전달해다가는 데이터로 구성된 시스템이다. 데이터 파이프라인의 기본적인 흐름은,

1. 데이터를 모아서 축적
2. 데이터 마트 구성
3. 시각화 도구

##### 데이터 수집

데이터 파이프라인은 데이터를 모으는 부분부터 시작한다. 수집 방법은,

1. 벌크형
   이미 어딘가에 있는 데이터를 정리해서 추출
   ex ) 데이터베이스와 파일 서버 등에서 정기적으로 데이터 수집

2. 스트리밍형
   차례대로 생성되는 데이터를 끊임없이 보냄
   ex) 모바일 어플리케이션, 임베디드 장비

##### 스트림 처리와 배치처리

1. 스트림 처리
   스트리밍 형 방법으로 받은 데이터를 실시간으로 처리.
   장기적인 데이터 분석에는 적합하지 않음.

2. 배치 처리
   정리된 데이터를 효율적으로 가공하기 위한 처리.
   장기적인 데이터 분석을 위해 대량의 데이터를 저장하고 처리하는데 적합한 분산 시스템이 필요.

##### 분산 스토리지

여러 컴퓨터와 디스크로 구성된 스토리지 시스템이다. 데이터 저장 방법으로,

1. 객체 스토리지
   한 덩어리로 모인 데이터에 이름을 부여해서 파일로 저장.
   ex ) Amazon S3

2. NoSQL 데이터베이스
   많은 데이터를 읽고 쓰기에 유리.

##### 분산 데이터 처리

분산 스토리지에 저장된 데이터를 처리하기 위해, 분산 데이터 처리 프레임워크가 필요하다. ex) MapReduce
주 역할은, 나중에 분석하기 쉽도록 데이터를 가공해서 그 결과를 외부 데이터베이스에 저장하는 것이다.
빅데이터를 SQL 로 집계하는 방법으로,

1. 쿼리 엔진
   Hive, 대화형 쿼리엔진

2. 데이터 웨어하우스 제품
   ETL.
   데이터를 추출하고 가공한후, 데이터 웨어하우스에 로드한다.

##### 워크플로우 관리

데이터파이프라인이 복잡해지면, 한곳에서 제어하지 않으면 전체 움직임 파악이 어렵다.

##### 데이터 웨어하우스와 데이터 마트

![](/image/bigdata_data_pipeline_warehouse.png)

1. 데이터 소스
   RDB 나 로그 등을 저장하는 파일 서버

2. ETL 플로세스
   데이터 소스에 보존된 raw data 를 추출하고 필요에 따라 가공한 후 데이터 웨어하우스에 저장하기까지의 흐름

3. 데이터 마트
   데이터웨어 하우스에서 필요한 데이터만을 추출하여 데이터마트를 구축

##### 데이터 레이크

![](/image/bigdata_data_pipeline_lake.png)

모든 데이터를 원래의 형태로 추적해두고 나중에 필요에 따라 가공하는 구조가 필요하다.
이 데이터 축적 장소가 데이터 레이크이다. 분산 스토리지가 데이터 레이크로 이용된다.
데이터 레이크의 데이터를 가공하기 위해 MapReduce 같은 분산 데이터 처리 기술이 필요하다.

##### 데이터 분석 기반을 단계적으로 발전시키기

1. 데이터 엔지니어
   시스템의 구축 및 운용, 자동화

2. 데이터 분석가
   데이터에서 가치있는 정보 추출

##### 확증적 데이터 분석과 탐색적 데이터 분석

1. 확증적 데이터 분석
   가설을 세우고 검증.
   통계학적 모델링에 의한 데이터 분석.

2. 탐색적 데이터 분석
   데이터를 보며 의미를 읽어냄.
   데이터를 시각화하여 사람의 힘으로 의미를 읽어냄

---

빅데이터를 지탱하는 기술 <니시다 케이스케>