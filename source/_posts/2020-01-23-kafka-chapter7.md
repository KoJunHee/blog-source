---
layout: post
title:  "[카프카] 7장_데이터 파이프라인 구축"
date:   2020-01-26
categories: Kafka
---

데이터 파이프라인을 직접 구성해본다. 다음 애플리케이션을 사용한다.

1. 아파치 나이파이
2. 엘라스틱 파일비트
3. 엘라스틱 엘라스틱서치
4. 엘라스틱 키바나

## 1. 카프카를 활용한 데이터 흐름도

![](/image/kafka_chapter07_01.png)

카프카에서 발생하는 로그를 이용해 데이터 흐름도를 구성해본다.

아파치 나이파이는 데이터 처리 흐름을 정의하고, 정의된 흐름대로 자동으로 실행해주는 애플리케이션이다.

1. 데이터 흐름을 처리하기 위한 워크플로우
2. 데이터 처리

## 2. 파일 비트를 이용한 메세지 전송

카프카의 로그를 카프카의 토픽으로 전송하려면 프로듀서가 필요하다. 프로듀서는,

1. 카프카 클라이언트 라이브러리를 이용해 프로그램으로 직접 구현
2. 오픈소스 애플리케이션 이용. 여기서는 파일 비트.

## 3. 나이파이를 이용해 메세지 가져오기

이제 컨슈머를 이용해 카프카 토픽으로부터 메세지를 가져와와야한다. 컨슈머는,

1. 프로그래밍 언어로 직접 구현
2. 오픈소스 애플리케이션 이용. 여기서는 나이파이.

#### 3.1 나이파이를 이용한 컨슈머 설정

![](/image/kafka_chapter07_02.png)

프로세서를 추가하는 화면이다.

프로세서는 나이파이에서 데이터 처리를 위한 각각의 컴포넌트이다. AMQP 컨슘, 파일로 저장, 전송하기 등 여러가지 작업이 가능하다.

ConsumeKafka 프로세서를 추가하고 재생 버튼을 누르면, 설정한 브로커의 토픽에서 메세지를 가져오기 시작한다.

컨슈머가 잘 동작하는지 확인하는 방법은,

1. 나이파이에서 컨슈머 프로세서를 실행 시킨 후,

2. 카프카 컨슈머 그룹 리스트에서, 등록한 컨슈머 그룹이 잘 등록되었는지 확인한다.

   등록한 컨슈머 그룹 : ConsumeKafka 프로세서의 Properties 를 정의할 때 그룹 ID 를 기입했음.

## 4. 실시간 분석을 위해 엘라스틱서치에 메세지 저장

이제, 가져온 메세지들을 나이파이의 또 다른 프로세서를 이용해 엘라스틱서치에 저장하겠다.

엘라스틱서치는 엘라스틱 사의 분산형 RESTFul 검색 및 분석 엔진이다. 전문 검색 질의를 이용해 원하는 데이터 분석을 빠르게 할 수 있는 애플리케이션이다.

#### 4.1 나이파이를 이용해 엘라스틱서치로 데이터 전송

PutElasticsearchHttp 프로세서를 추가한다. 데이터를 엘라스틱서치로 넣어주는 역할을 한다.

그리고 다음 화면처럼, ConsumeKafka 와 연결한다.

![](/image/kafka_chapter07_03.png)

데이터 흐름 중에 뒤에 있는 프로세서에서 처리 속도가 느려 바로 처리하지 못하거나 프로세서에 문제가 발생한 경우, 두 프로세스를 연결하는 큐에 레코드가 쌓인다.

## 5. 키바나를 이용해 엘라스틱서치에 저장된 데이터 확인

웹브라우저를 이용해 원하는 시간대에 발생한 로그들을 확인할 수 있고, 필터 기능으로 원하는 패턴의 로그만 빠르게 검색 가능하다.

각 브로커에서 수집되는 로그가 카프카의 토픽에 있기 때문에, 엘라스틱 서치에 전송하는 것 외에 추가로 하둡이나 로컬에 저장하길 원하면, 다음 화면처럼 나이파이의 PutHDFS 프로세서를 추가해 쉽게 하둡 등의 저장소에 저장할 수 있다.

![](/image/kafka_chapter07_04.png)

## 6. 현재의 토픽을 이용해 새로운 토픽으로 메세지 재생산

![](/image/kafka_chapter07_05.png)

이번에는, 메세지의 양이 굉장히 많은 토픽의 내용 중 필요한 메세지만 꺼내서 다시 새로운 토픽으로 메세지를 보내는 방법을 정리한다.

전체적인 데이터 흐름은,

1. 나이파이 컨슈머가 peter-log 로부터 로그 메세지를 가져오면서 호스트 이름을 확인한다.
2. peter-log 토픽으로 로그 메세지를 보내는 서버는 peter-kafka001,peter-kafka002, peter-kafka003 모두 3대이다.
3. 각각의 메세지마다 호스트 이름이 peter-kafka001,ppeter-kafka002, ppeter-kafka003 이 기록되어 있다.
4. 전체 메세지 중에 호스트 이름이 peter-kafka001메세지만 peter-kafka001토픽으로 다시 전송하고,
5. 나머지 메세지는 peter-failure 토픽으로 전송한다.

#### 6.1 나이파이를 이용한 토픽별 라우팅

나이파이에서 토픽의 메세지를 가져와서 peter-kafka001 에서 온 메세지인지 확인한 후에 peter-kafka001 토픽으로 전송해야한다. 

이를 위해, 나이파이의 EvaluateJsonPath, RouteOnAttribute 프로세서를 추가해서 라우팅 작업을 한다.

1. EvaluateJsonPath 프로서는, 토픽으로 전송된 JSON 의 beat.hostname 을 읽어 호스트 이름을 구분한다.

2. RouteOnAttribute 프로세서는, attrubute 를 이용해 라우팅을 한다.

마지막으로, 카프카 프로듀서 2개를 추가한다.

1. 호스트명이 peter-kafka001 인 메세지를  peter-kafka001 토픽으로 전송할 프로듀서
2. 그 외 메세지를  peter-failure 토픽으로 전송할 프로듀서

최종 플로우는 다음과 같다.

![](/image/kafka_chapter07_06.png)

---

카프카, 데이터 플랫폼의 최강자 <고승범, 공용준>