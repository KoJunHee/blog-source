---
layout: post
title:  "[빅데이터를 지탱하는 기술] 4장_빅데이터 분산처리"
date:   2019-01-02
categories: Big Data
---

## 1. 벌크 형과 스트리밍 형의 데이터 수집

데이터 수집 방법으로 두 가지 방법이 있다. 

이 챕터에서는 각각의 방법으로, 분산 스토리지에 데이터가 저장되기 까지의 흐름을 정리한다.

1. 벌크 형 
2. 스트리밍 형

##### 객체 스토리지와 데이터 수집

빅데이터는 확장성이 높은 분산 스토리지에 저장된다. 분산 스토리지로,

1. 분산형 데이터베이스

2. 대량으로 파일을 저장하는 객체 스토리지

   객체 스토리지는 다수의 컴퓨터를 사용해 파일을 여러 디스크에 복사해서 데이터 중복화 및 부하 분산을 실현한다.

   객체 스토리지의 구조는 데이터 양이 많을 때는 우수하지만, 소량의 데이터에 대해서는 비효율적이다.

   하둡의 HDFS, 클라우드 서비스의 Amazon S3 가 대표적이다.

##### 데이터 수집

데이터 수집이란, 수집한 데이터를 가공해 집계 효율이 좋은 분산 스토리지를 만드는 일련의 프로세스이다. 

작은 데이터는 적당히 모아서 하나의 큰 파일로 만들어 효율을 높이는데 도움이 된다. 

파일이 지나치게 크면, 네트워크 전송 시간이 오래 걸려 오류 발생률이 높다. 

##### 벌크 형 데이터 전송

![](/image/big_data_bulk_data.png)

전통적인 데이터 웨어하우스에서는 주로 벌크 형 방식으로 데이터베이스나 파일 서버 또는 웹 서비스 등에서 각각의 방식 (SQL, API ...) 으로 정리해 데이터를 추출한다.

처음부터 분산 스토리지에 데이터가 저장되어 있지 않으면 데이터 전송을 위한 ETL 서버를 설치한다. 

데이터 전송의 신뢰성이 중요하면 벌크형 도구를 사용하는 것이 좋다.

##### 파일 사이즈의 적정화

ETL 프로세스는 하루마다 또는 한시간 마다의 간격으로 정기적인 실행을 하므로 그 동안 축적된 데이터는 하나로 모인다.

데이터 양이 많을 떄는 한 달씩이나 하루 단위로 전송하도록 작은 태스크로 분해해 한 번의 태스크 실행이 커지지 않도록 조정해야한다. 

워크 플로우 관리 도구를 사용하면 쉽게 관리 할 수 있다.

##### 스트리밍 형의 데이터 전송

![](/image/big_data_message_delivery.png)

계속해서 전송되어 오는 작은 데이터를 취급하기 위한 데이터 전송이다.

이러한 데이터 전송은 다수의 클라이언트에서 계속 작은 데이터가 전송된다. 이러한 데이터 전송 방식이 메세지 배송 (Message Delivery) 이다. 

보내온 메세지를 저장하는 방법으로,

1. NoSQL 데이터베이스

   Hive 와 같은 쿼리 엔진으로 NoSQL 데이터베이스에 연결해 데이터를 읽을 수 있다. 

2. Message Queue

   데이터를 일정 간격으로 꺼내고 모아서 분산 스토리지에 저장한다.

##### 웹 브라우저에서 메세지 배송 

![](/image/big_data_message_web_browser.png)

1. 상주형 로그 수집 소프트웨어

   자체 개발한 웹 애플리케이션 등에서는 웹 서버 안에서 메세지를 만들어서 배송한다. 전송 효율을 높이기 위해 서버상에서 일단 데이터를 축적해 놓고 나중에 모아서 보내는 경우가 있다. 이 때, Fluentd 나 Logstash 같은 상주형 로그 수집 소프트웨어가 자주 사용된다.

2. 웹 이벤트 추적

   자바스크립트를 이용해 웹 브라우에서 직접 메세지를 보내는 경우도 있다.

##### 모바일 앱에서 메세지 배송

![](/image/big_data_message_mobile.png)

1. MBaaS

   모바일 앱에서는 서버를 직접 마련하는 것이 아니라, MBaaS (Mobile Backend as a Serivce) 라는 백엔드의 각종 서비스를 이용할 수 있다. 

2. SDK

   모바일 앱이 오프라인이 되었을 때는 발생한 이벤트를 SDK 내부에 축적하고 온라인 상태 되었을 때 모아서 보낼 수 있다.

##### 디바이스에서 메세지 배송

![](/image/big_data_message_device.png)

MQTT (MQ Telemetry Transport) 는 TCP/IP 를 이용하여 데이터 전송하는 프로토콜 중 하나이다. 일반적으로 Pub/Sub 메세지 배송 구조이다. 

##### 메세지 배송의 공통화

메세지가 처음 생성되는 기기를 클라이언트, 해당 메세지를 먼저 받는 서버를 프론트엔드라고 한다.

프론트 엔드는 단지 데이터를 받는 것에 전념하고, 그 이후의 문제는 백엔드의 공통 시스템에 맡길 수 있다.

## 2. 성능, 신뢰성 : 메세지 배송의 트레이드오프

이 챕터는 메세지 브로커를 중심으로 메세지 배송 구조와 한계를 정리한다.

##### 메세지 브로커

메세지 배송에 의해 보내진 데이터를 분산 스토리지에 저장할 때, 데이터 양이 적을 때는 문제가 되지 않지만 쓰기의 빈도가 증가하면 디스크 성능의 한계에 도달해 더 쓸 수 없게 될 우려가 있다.

대량의 메세지를 안정적으로 받기 위해서는 빈번한 쓰기에도 견딜 수 있는 성능이 높고, 필요에 따라 성능을 얼마든지 올릴 수 있는 스토리지가 필요하다.

분산 스토리지가 반드시 이 성격을 가질 수 있다고 할 수 없기 때문에, 메세지를 일시적으로 축적하는 중산층이 설치된다. 이것이 메세지 브로커이다.

ex) Apache Kafka, Amazon Kinesis

##### push 형, pull 형

송신 측의 제어로 데이터를 보내는 방식을 push 형, 수신 측 주도로 데이터를 가져오는 것을 pull 형이라고 한다.

메세지 브로커에 데이터를 push 하는 것을 producer, pull 하는 것을 consumer 라고 한다.

push 형의 메세지 배송은 모두 메세지 브로커에 집중 시키고 거기에서 일정한 빈도로 꺼낸 데이터를 분산 스토리지에 기록한다.

또한, pull 형의 메세지 배송은 파일 사이즈 적정화에도 도움이 된다. consumer 는 메세지 브로커로부터 일정한 간격으로 데이터를 취해 적당히 모아진 데이터를 분산 스토리지에 저장한다.

##### 메세지 라우팅

메세지 브로커에 써넣은 데이터는 다수의 다른 consumer 에서 읽을 수 있다. 이를 통해 메세지가 복사되어 데이터를 여러 경로로 분기 시킬 수 있다. 이것이 메세지 라우팅이다.

예를 들어, 메세지 일부를 실시간 장애 감지를 사용하면서, 같은 메세지를 장기적인 데이터 분석을 위한 분산 스토리지에 저장하는 것도 가능하다.

##### 메세지 배송 신뢰성 문제와 세 가지 설계 방식

대부분의 경우 다음 중 하나를 보장하도록 설계된다.

1. at most once

   메세지는 한 번만 전송된다. 도중에 전송 실패로 사라질 가능성이 있다.

2. exactly once

   메세지는 손실 되거나 중복 없이 한 번만 전달된다.

   네트워크 상에 두 개의 노드가 있는 경우 양쪽의 통신 내용을 보장하기 위해 coorninator 가 필요하다. 문제가 생기면 송신 측과 수신 측 모두 서로의 정보를 코디네이터에게 전달해서 문제가 발생하면 코디네이터의 지시에 따라 해결할 수 있다.

   그러나 분산 시스템에서는 코디네이터와의 통신이 끊길 수 있고 코데네이터가 정지될 수도 있다. 따라서 코디네이터의 부재 시에 어덯게 할 것인지에 대한 consensus 가 필요하다. 보통, 단시간 장애 가능성은 받아 들인다.

   또한, 코디네이터의 판단에만 따르고 있으면 시간이 너무 소요된다. 

   그래서 메세지 배송 시스템에서는 코디네이터를 도입하지 않고 at least once 를 따른다. 

3. at least once

   메세지는 확실히 전달된다. 단, 같은 것이 여러번 전달될 가능성이 있다.

   메세지가 재전송되어도 그것을 없앨 수 있는 구조가 있으면 보기에 중복이 없는 것처럼 할 수 있다. 이러한 구조를 '중복 제거' 라고 한다. 

   예를 들어, TCP 는 메세지 수신 확인을 위해 'ack' 플래그를 도입했다. 메세지 재전송에 의한 중복이 발생하지만, 모든 TCP 패킷에서는 이것을 식별하는 시퀀스 번호를 이용해 중복 제거가 이뤄진다.

   대부분의 메세지 배송 시스템은 at least once 를 보장하는 한편, 중복 제거는 이용자에게 맡기고 있어서 TCP/IP 처럼 자동으로 중복을 제거해주지 않는다. (ex) Apache Kafka, Apache Flume, Logstash

##### 중복 제거는 높은 비용의 오퍼레이션

중복 제거 방법으로 다음과 같은 방법이 있다.

1. 오프셋 이용

   각 메세지에는 파일 안의 시작 위치 (오프셋) 를 붙인다.

   메세지가 중복되어도 같은 파일의 같은 장소를 덮어쓸 뿐이므로 문제되지 않는다.

   벌 크형 데이터 전송과 같이 데이터양이 고정된 경우에 사용한다.

2. 고유 ID 이용

   모든 메세지에 UUID 등의 고유 ID 를 지정한다.

   메세지가 늘어남에 따라 ID 가 증가하므로 그것을 어떻게 관리하느냐가 문제이다.

   스트리밍 형의 메세지 배송에서 자주 사용된다. 

##### End to End 신뢰성

클라이언트가 생성한 메세지를 최종 도달 지점인 분산 스토리지에 기록하는 단계에서 중복 없는 상태로 해야한다.

중간에 한 부분이라도 at most once 가 있으면 메세지를 빠뜨릴 가능성이 있고, at least once 가 있으면 중복될 수 있다. 

신뢰성이 높은 메세지 배송을 실현하려면 중간 경로를 모두 at least once 로 통일한 후 클라이언트 상에서 모든 메세지에 고유 ID 를 포함하도록 하고 경로의 말단에서 중복 제거를 실행해야한다.

##### 고유 ID 를 사용한 중복 제거 방법

두가지 방법이 있다.

1. 분산 스토리지로 NoSQL 데이터베이스 사용

   Cassandra 나 Elasticsearch 등은 데이터를 쓸 대 고유 ID 를 지정하게 되어 있어 동일한 ID 의 데이터는 덮어쓴다.

2. SQL

   보내온 데이터는 일단 그대로 객체 스토리지 등에 저장하고, 나중에 읽어 들이는 단계에서 중복을 제거한다. 

   Hive 와 같은 배치형 쿼리 엔진에서 실행할 수 있다.

##### 데이터 수집 파이프라인

![](/image/big_data_stream_pipeline.png)

일련의 프로세스를 거쳐 마지막으로 데이터를 구조화해서 열 지향 스토리지로 변환함으로써, 장기간의 데이터 분석에 적합한 스토리가 완성된다. 이것인 데이터 수집 파이프라인이다.

실제로 어떤 파이프라인을 만들지는 요구사항에 따라 다르므로, 필요에 따라 시스템을 조합한다. 

예를 들어, 쓰기 성능에 불안감이 없으면 메세지 브로커가 불필요 하므로 클라이언트에서 직접 NoSQL 데이터베이스에 데이터를 써도 된다. 중복이 허용된다면 중복 제거를 생략할 수 있다.

##### 중복을 고려한 시스템 설계

스트리밍 형의 메세지 배송 방식에서는 중간에 중복 제거 방식을 도입하지 않으면 중복 가능성이 있다고 생각하면 된다.

신뢰성이 중시되는 경우에는 스트리밍 형의 메세지 배송을 피하는 것이 좋다.

예를 들어, 과금 데이터같은 오차가 불허용 되는 경우 트랜잭션 처리르 지원하는 데이터베이스에 직접 애플리케이션이 기록해야한다. 그 후에 벌크 형의 데이터 전송을 함으로써 중복도 결손도 확실히 피해야한다.











## 3. TODO 



##### ㅇㅇㅇ

팩트 테이블 작성 방법으로,

1. 추가

   새로 도착한 데이터만을 증분으로 추가

2. 치환

   과거 데이터를 포함하여 테이블 전체 치환

##### 테이블 파티셔닝

위의 '추가' 방법은 다음 문제가 있다.

1. 추가에 실패한것을 알아채지 못하면, 팩트 테이블의 일부에 결손
2. 추가를 잘못해서 여러번 실행하면, 일부 중복
3. 나중에 팩트 테이블 다시 만들고 싶으면, 관리 복잡

그래서 파티셔닝이 필요하다.

하나의 테이블을 여러 물리적인 파티션으로 나눠서 파티션 단위로 정리하여 데이터를 쓰거나 삭제하는 것이다.

##### 집계 테이블

팩트 테이블을 어느 정도 모아서 집계하면 데이터의 양이 줄어든다. 이것은 집계 테이블이라고 한다.

각 칼럼이 취하는 값의 범위란, 카디널리티이다. '성별' 과 같이 취할 수 있는 값이 적은 것은 카디널리티가 작은 것이다.

집계 테이블을 작게 하려면 모든 칼럼의 카디널리티를 줄여야한다.

##### 스냅샷 테이블, 이력 테이블

마스터 데이터처럼 업데이트 될 가능성이 있는 테이블은,

정기적으로 테이블을 통째로 저장하는 스탭샷 테이블, 또는 변경 내용만을 저장하는 이력 테이블로 관리할 수 있다.

##### 디멘전을 추가하여 비정규화 테이블 완성시키기

팩트 테이블과 디멘젼 테이블을 결합하여 비정규화 테이블을 만든다.

---

빅데이터를 지탱하는 기술 <니시다 케이스케>

