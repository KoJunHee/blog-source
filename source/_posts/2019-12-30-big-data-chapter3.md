---
layout: post
title:  "[빅데이터를 지탱하는 기술] 3장_빅데이터 분산처리"
date:   2019-12-30
categories: Big Data
---

## 1. 대규모 분산 처리의 프레임워크

비구조화 데이터를 읽어 들여 열 지향 스토리지로 변환하는 과정에서, 데이터의 가공 및 압축을 위해 많은 컴퓨터 리소스가 소비된다.
그래서 사용하는 것이 Hadoop, Spark 같은 분산 처리 프레임워크다.

##### 구조화 데이터, 비구조화 데이터, 스키마리스 데이터

1. 구조화 데이터
   스키마가 명확하게 정의된 데이터.
   기존의 데이터 웨어하우스에서는 항상 구조화 데이터로 축적하는 것이 일반적이었다.

2. 비구조화 데이터
   스키마가 없는 데이터.
   이 상태로는 SQL 로 제대로 집계할 수 없다.

3. 스키마리스 데이터
   CSV, JSON, XML 등의 데이터는 서식은 정해져 있지만, 칼럼 수나 데이터 형은 명확하지 않다.

##### 데이터 구조화의 파이프라인

![](/image/structured_data.png)

분산 스토리지에 수집된 데이터는 명확한 스키마를 갖지 않아 그대로는 SQL 로 집계할 수 없다.
그래서, 먼저 스키마를 명확하게 한 테이블 형식으로 변환해야한다.
구조화된 데이터는 데이터 압축률을 높이기 위해 열 지향 스토리지에 저장한다. 

##### 열 지향 스토리지의 작성

Hadoop 의 열 지향 스토리지는,

1. Apache ORC
   처음에 스키마를 정한 후 데이터를 저장

2. Apache Parquet
   스키마리스에 가까운 데이터 구조로 되어 있어서 JSON 같은 데이터도 그대로 저장

##### Hadoop

![](/image/big_data_hadoop.png)

단일 소프트웨어가 아니라 분산 시스템을 구성하는 다수의 소프트웨어로 이루어진 집합체이다.
기본 구성 요소는,

1. 분산 파일 시스템
   HDFS.
   다수의 컴퓨터에 파일을 복사하여 중복성을 높이는 특징이 있다.

2. 리소스 관리자
   YARN, Mesos.
   YARN 은 애플리케이션이 사용하는 CPU 코어와 메모리를 컨테이너라는 단위로 관리한다.
   Hadoop 에서 분산 애플리케이션을 실행하면 YARN 이 클러스터 전체의 부하를 보고 비어 있는 호스트부터 컨테이너를 할당한다.
   어느 애플리케이션에 얼마만큼의 리소스를 할당할 지 관리해서 모든 애플리케이션이 실행되도록 제어한다.

3. 분산 데이터 처리
   MapReduce, Tez.
   MapReduce 도 YARN 위에서 동작하는 분산 애플리케이션 중 하나이다.

##### 쿼리 엔진

![](/image/big_data_hive_mr.png)

하둡에서는 다수의 쿼리 엔진이 개발되었다. 총칭해서 SQL-on-Hadoop 이라고 한다.
SQL 등의 쿼리 언어에 의한 데이터 집계가 목적이면, 이를 위해 설계된 쿼리 엔진을 사용한다.
Apache Hive 가 대표적이다. 쿼리를 자동으로 MapReduce 프로그램으로 변환하는 소프트웨어이다.
시간이 걸리는 배치 처리에는 적합하나, 애드 혹 쿼리를 여러 번 실행하는데는 부적합하다.
왜냐하면 위 그림처럼, 스테이지가 바뀔 때 대기 시간이 있기 때문이다.

![](/image/big_data_hive_tez.png)

Apache Tez 는 Hive 를 가속화하기 위해 개발되었다. 기존의 MapReduce 를 대체할 목적이다.
Hive on MR 은, 1회의 MapReduce 스테이지가 끝날 때까지 다음의 처리를 진행할 수 없다.
Hive on Tez 는, 위 그림처럼 스테이지의 종료를 기다리지 않고 데이터를 차례대로 후속 처리에 전달하여 쿼리 전체 실행 시간을 단축한다.

##### 대화형 쿼리엔진

![](/image/big_data_presto.png)

Apache Impala 와 Presto 가 대표적이다.
YARN 과 같은 리소스 관리자를 사용하지 않고, SQL 의 실행만으로 분산처리를 구현한다.
순간 최대 속도를 높이기 위해 모든 오버 헤드가 제거되어, 사용할 수 있는 리소스를 최대한 활용하여 쿼리를 실행한다.

##### Spark

![](/image/big_data_spark.png)

MapReduce, Tez 모두 데이터 처리 과정에서 만들어진 중간 데이터를 디스크에 기록한다.
Spark 는 대량의 메모리를 활용하여 고속화를 실현한다.
Hadoop 을 대체하는 것이 아니라, MapReduce 를 대체하는 존재다.

## 2. 쿼리 엔진

![](/image/big_data_hive_presto.png)

##### 데이터 마트 구축의 파이프라인

1. Hive
   분산 스토리지에 저장된 데이터를 구조화하고 열 지향 스토리지 형식으로 저장

2. Presto
   완성한 구조화 데이터를 결합, 집계하고 비정규화 테이블로 만든 데이터 마트에 써서 보냄

##### Hive 에 의한 구조화 데이터 작성

```sql
hive> CREATE EXTERNAL TABLE access_log_csv (...)
```

CSV 파일을 읽어들여 외부 테이블을 정의한다.
외부테이블이란, Hive 의 외부에 있는 특정 파일을 참고해 마치 거기에 테이블이 존재하는 것처럼 읽어 들이기 위해 지정한다.
쿼리를 실행할 때마다 매번 텍스트를 읽어들이기 때문에 느리다. 그래서 열 지향 스토리지로 변환해야한다.

##### 열 지향 스토리지로의 변환

```sql
hive> CREATE TABLE access_log_orc STROED as ORC as SELECT ..
```

텍스트 데이터를 열 지향 스토리지로 변환함으로써 데이터의 집계가 크게 고속화된다.

##### Hive 로 비정규화 테이블 작성하기

데이터 구조화가 완료되면 데이터 마트를 구축해야한다. 즉, 테이블을 결합 및 집약해서 '비정규화 테이블' 을 만든다.
Preso 와 같은 대화형 쿼리 엔진, Hive 같은 배치형 쿼리 엔진을 사용할 수 있다. 시간이 걸리는 배치 처리는 Hive 를 사용해야한다.
비정규화 테이블을 만드는 데 오랜 시간이 걸리므로, 가능한 효율적인 쿼리를 작성해야한다. 

1. 서브 쿼리 안에서 레코드 수 줄이기
   서브 쿼리 안에서 팩트 테이블을 작게 해야한다.
   데이터의 양의 감소 시킨 후에 테이블을 결합하는 것이 쿼리 실행 시간을 단축시킨다.

2. 데이터 편향 피하기
   분산 시스템의 성능을 발휘하기 위해서, 모든 노드에 데이터가 균등하게 분산되도록 해야한다.

##### 대화형 쿼리 엔진 Presto 구조

쿼리 실행의 지연을 감소시키는 목적으로 개발된 것이 대화형 쿼리 엔진이다.
Presto 의 특징은,

1. 플러그인 가능한 스토리지
   다양한 데이터 소스를 테이블로 참고할 수 있다.
   ex) 하나의 쿼리 안에서 분산 스토리지 상의 팩트 테이블과 MySQL 의 마스터 테이블을 조인할 있다.

2. CPU 처리의 최적화
   코드의 실행을 멀티 스레드화되어 단일 머신에서 수백 태스크나 병렬로 실행된다.
   그래서, CPU 이용 효율이 높다.

3. 인 메모리 처리에 의한 고속화
   모든 데이터 처리는 메모리 상에서 실시하고 메모리가 부족하면 여유가 생길 때까지 기다리거나 오류로 실패한다.

##### 데이터 분석의 프레임워크 선택하기

1. MPP Database
   비정규화 테이블을 고속으로 집계하는 데에 최적

2. Hive
   데이터 양에 좌우되지 않는 쿼리 엔진

3. Presto
   속도 중시, 대화식으로 특화된 쿼리 엔진

4. Spark
   분산 시스템을 사용한 프로그래밍 환경.
   ETL 프로세스에서 SQL 에 이르기 까지의 일련의 흐름을 하나의 데이터 파이프라인으로 기술 가능.

## 3. 데이터 마트의 구축

분산 시스템이 준비되면 시각화를 위해 데이터 마트를 만든다.

##### 팩트 테이블

팩트 테이블 작성 방법으로,

1. 추가
   새로 도착한 데이터만을 증분으로 추가

2. 치환
   과거 데이터를 포함하여 테이블 전체 치환

##### 테이블 파티셔닝

위의 '추가' 방법은 다음 문제가 있다.

1. 추가에 실패한것을 알아채지 못하면, 팩트 테이블의 일부에 결손
2. 추가를 잘못해서 여러번 실행하면, 일부 중복
3. 나중에 팩트 테이블 다시 만들고 싶으면, 관리 복잡

그래서 파티셔닝이 필요하다.
하나의 테이블을 여러 물리적인 파티션으로 나눠서 파티션 단위로 정리하여 데이터를 쓰거나 삭제하는 것이다.

##### 집계 테이블

팩트 테이블을 어느 정도 모아서 집계하면 데이터의 양이 줄어든다. 이것은 집계 테이블이라고 한다.
각 칼럼이 취하는 값의 범위란, 카디널리티이다. '성별' 과 같이 취할 수 있는 값이 적은 것은 카디널리티가 작은 것이다.
집계 테이블을 작게 하려면 모든 칼럼의 카디널리티를 줄여야한다.

##### 스냅샷 테이블, 이력 테이블

마스터 데이터처럼 업데이트 될 가능성이 있는 테이블은,
정기적으로 테이블을 통째로 저장하는 스탭샷 테이블, 또는 변경 내용만을 저장하는 이력 테이블로 관리할 수 있다.

##### 디멘전을 추가하여 비정규화 테이블 완성시키기

팩트 테이블과 디멘젼 테이블을 결합하여 비정규화 테이블을 만든다.

---

빅데이터를 지탱하는 기술 <니시다 케이스케>